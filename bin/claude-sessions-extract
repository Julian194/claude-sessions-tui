#!/usr/bin/env python3
"""
Fast metadata extraction for Claude session files.
Replaces the slow bash extract_meta() function.
"""
import re
import sys
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime
from pathlib import Path

# ANSI color codes
CYAN = "\033[0;36m"
YELLOW = "\033[0;33m"
NC = "\033[0m"


def extract_meta(filepath: str) -> tuple | None:
    """Extract metadata from a single session file."""
    try:
        path = Path(filepath)
        if not path.exists():
            return None

        # Session ID from filename
        sid = path.stem

        # Project name from parent directory
        proj = path.parent.name
        # Clean up project name (remove -Users-xxx-... prefix patterns)
        # Pattern: -Users-username-Documents-Workspace-projectname -> projectname
        proj = re.sub(r"^-Users-[^-]+-Documents-Workspace-?", "", proj)
        proj = re.sub(r"^-Users-[^-]+-code-?", "", proj)
        if not proj:
            proj = "~"  # Root workspace sessions

        # File stats (single syscall)
        stat = path.stat()
        mtime = int(stat.st_mtime)
        dt = datetime.fromtimestamp(stat.st_mtime)
        date = dt.strftime("%m-%d")
        full_date = dt.strftime("%Y-%m-%d")

        # Read file content for metadata extraction
        summary = "-"
        parent_sid = "-"

        with open(path, "rb") as f:
            # Read first chunk for parentSession (usually in first line)
            chunk = f.read(1000).decode("utf-8", errors="ignore")
            match = re.search(r'"parentSession":"([^"]*)"', chunk)
            if match:
                parent_sid = match.group(1)

            # Read more for summary (can be anywhere in first ~50KB)
            f.seek(0)
            chunk = f.read(50000).decode("utf-8", errors="ignore")
            match = re.search(r'"summary":"([^"]*)"', chunk)
            if match:
                summary = match.group(1)

        return (sid, date, proj, summary, mtime, parent_sid, full_date)

    except Exception:
        return None


def format_tsv(data: tuple) -> str:
    """Format tuple as TSV line."""
    sid, date, proj, summary, mtime, parent_sid, full_date = data
    return f"{sid}\t{date}\t{proj}\t{summary}\t{mtime}\t{parent_sid}\t{full_date}"


def format_date_header(full_date: str) -> str:
    """Format a date header line."""
    try:
        dt = datetime.strptime(full_date, "%Y-%m-%d")
        formatted = dt.strftime("%A, %B %d, %Y")
    except ValueError:
        formatted = full_date
    return f"---HEADER---\t{CYAN}{formatted} {'─' * 25}{NC}\t-\t-\t0\t-\t-"


def main_stream(files: list[str]):
    """Stream mode: output with formatting as we go (for progressive loading)."""
    current_date = ""

    for filepath in files:
        data = extract_meta(filepath)
        if not data:
            continue

        sid, date, proj, summary, mtime, parent_sid, full_date = data

        # Insert date separator when date changes (root sessions only)
        if parent_sid == "-" and full_date != current_date:
            if current_date:
                # Output header for previous date group
                print(format_date_header(current_date))
            current_date = full_date

        # Format output - branches get visual prefix
        if parent_sid != "-":
            print(f"{sid}\t{YELLOW}  └─ {date}{NC}\t{proj}\t{summary}\t{mtime}\t{parent_sid}\t{full_date}")
        else:
            print(format_tsv(data))

    # Final date header
    if current_date:
        print(format_date_header(current_date))


def main_batch(files: list[str]):
    """Batch mode: extract all, output TSV (for caching)."""
    # Use parallel processing for many files
    if len(files) > 10:
        with ProcessPoolExecutor(max_workers=8) as executor:
            results = executor.map(extract_meta, files)
            for data in results:
                if data:
                    print(format_tsv(data))
    else:
        # Sequential for few files (less overhead)
        for f in files:
            data = extract_meta(f)
            if data:
                print(format_tsv(data))


def main():
    stream_mode = "--stream" in sys.argv

    # Read file paths from stdin (one per line)
    files = [line.strip() for line in sys.stdin if line.strip()]

    if not files:
        return

    if stream_mode:
        main_stream(files)
    else:
        main_batch(files)


if __name__ == "__main__":
    main()
